<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Project on xym-ee</title>
    <link>https://xym.work/tags/project/</link>
    <description>Recent content in Project on xym-ee</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 29 Aug 2024 23:30:30 +0800</lastBuildDate>
    <atom:link href="https://xym.work/tags/project/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>[project]2023 年电子设计竞赛：运动控制与目标追踪系统的设计</title>
      <link>https://xym.work/blog/laser-track.html</link>
      <pubDate>Thu, 29 Aug 2024 23:30:30 +0800</pubDate>
      <guid>https://xym.work/blog/laser-track.html</guid>
      <description>0.简介 来源于 2023 年大学生电子设计竞赛的题目。导师正好是电赛的指导老师，我参加过2019年电赛，然后就帮忙一起指导一下。&#xA;出方案，方法验证，分工。&#xA;设计制作一个运动目标控制与自动追踪系统。&#xA;需要做两套系统，两套系统之间无通信&#xA;位置控制系统，红色激光模拟目标运动，激光点画出指定的矩形 自动追踪系统，绿色激光用来指示，绿色激光点跟踪红色激光运动 自动追踪系统只在完成提高题时需要。&#xA;1.赛题分析与方案设计 根据题目，有这几个比较重要的需要实现的功能&#xA;1.红色激光点能做一个固定大小的矩形运动 2.黑色胶带贴一个矩形框，红色激光点可以沿着黑框运行 3.绿色激光点追踪红色激光点运行 第 1 点，基础题的要求，激光点可以跟着铅笔线画一个方框。可以肯定的是铅笔线肯定不是用来做图像识别的，而且位置控制系统和屏幕的摆放都有严格的距离要求，那么在红激光点的位置上不需要做闭环控制，根据几何参数做计算，找到屏幕坐标系中点的位置和云台两个电机转角的关系，直接开环运动即可。需要在硬件上下点功夫，精度严重依赖几何参数，可以直接做一个架子，云台和屏幕都固定死了，😂，这种应试的项目不要不违反要求都是能做的。此功能要实现的代码的功能&#xA;实现指定两点之间的直线运动 第 2 点，黑胶带显然是要做视觉识别的，矩形运动比较关键的位置是 4 个顶点。有了 4 个点其实就可以计算出矩形边上所有的点了。这个目标的思路，一个也是纯开环控制，和功能 1 一样 ，有了四个点以后，有没有黑框就不重要了。&#xA;需要一个能给我发送矩形 4 个点的传感器(矩形 4 点传感器) 具体是 openmv 、linux 板用 opencv 不重要 只要能按顺序发来 ABCD 在屏幕上的坐标位置就行 第 3 点，位置控制系统(红色激光)不需要大的功能上的改动了。考虑目标追踪系统该如何设计。可以肯定的是要做一个位置上的闭环控制，目标点是红色激光的位置，一个容易想到的思路是识别绿色激光点的位置，这就就有了两个点的位置误差。但是这样的话要在一块板上同时处理红绿两个点实现起来可能要花点时间。我的思路：直接将摄像头固定到云台上，控制目标是将红色激光点保持在视野中央，有没有绿激光点不重要，绿激光只是给人看的指示云台指向位置的一个挂件。可以吧绿色激光调到足够暗，人勉强看到就好了，😂，应试项目，所有的处理都是符合规则的。这样的话为视觉识别那一块的要求就不高了。甚至如果是闭环控制的话，不需要红激光点在屏幕上的真实坐标，像素坐标位置就可以了&#xA;需要一个固定在云台上的激光点位置传感器 同样用什么方法实现、什么设备实现的不重要 只要能发回来红色激光点的像素坐标 (x,y) 就行 那么设计方案就出来了。两个系统都分为运动控制部分 + 视觉检测部分，两个部分相对独立，可以使用串口来完成通信。&#xA;云台使用伺服电机，可以接收位置控制指令或速度控制指令，使用 MCU 实现运动控制。&#xA;位置控制系统(红色激光点)的摄像头不需要安装在云台，但是相对于屏幕的位置要固定，视觉检测部分和运动控制部分的通信内容：矩形 ABCD 四个顶点在屏幕上的坐标。&#xA;point_t rectangle[4]; 目标追踪系统的摄像头要安装到云台上，视觉检测部分和运动控制部分的通信内容：红色激光点的像素坐标&#xA;pix_t red_point_pix; 通过串口发送时，加上帧头帧尾和校验字节，方便解析、防止传输出错。&#xA;电赛三人小队可分工一人负责控制部分，另一人负责图像处理部分，各自对接通信协议即可。&#xA;相对来说，位置控制系统的视觉检测部分需要处理的东西会多一些，可以使用 linux 开发板跑调 OpenCV 库，跟踪系统的视觉检测部分只需要识别一个激光点，OpenMV 也可以胜任。</description>
    </item>
    <item>
      <title>[project]搭载于密闭环境检测无人机的环境数据采集与上报模块</title>
      <link>https://xym.work/blog/data-collector-rt.html</link>
      <pubDate>Wed, 28 Aug 2024 13:00:00 +0800</pubDate>
      <guid>https://xym.work/blog/data-collector-rt.html</guid>
      <description>0. 介绍 这是一个物联网项目，合作公司的主要业务是使用无人机进行密闭环境的无人检测，如船舶、大型锅炉、化工厂储罐等内部观察检测。该项目需要开发一套用于密闭环境近观检测的无人机系统，涵盖硬件设计、软件开发与系统集成。该系统由无人机端、地面监控端和数据传输与系留供电模块组成，专门用于密闭空间内的精细检测任务。无人机端搭载高清相机、飞控系统，以及一个基于 STM32F407 的环境数据采集与上报模块。该模块通过外挂的 W5500 芯片与无人机局域网内的机载工控机进行通信，采用 UDP 协议实现数据传输。&#xA;我负责环境数据采集与上报模块的所有软件功能开发。&#xA;源码仓库&#xA;1. 硬件方案 此项目我不负责硬件设计部分，但这里也简单介绍一下硬件方案。&#xA;主控芯片：STM32F407VET6 网络芯片：W5500 W5500(datasheet)是一款全硬件 TCP/IP 协议栈以太网控制器，内部集成了以太网数据链路层（MAC）和以太网物理层（PHY），内嵌的 8 个独立硬件 Socket 可以进行 8 路独立通信。使用标准 4 线 SPI 接口与主机进行通信。&#xA;传感器部分&#xA;1 个高精度温度传感器 MCP9808 IIC 接口 2 个电化学可燃气体浓度传感器 UART 接口 3 个 ToF 距离传感器 IIC 接口 此外，还有共 20 个 GPIO 用来控制灯光、电源的开关。&#xA;激光测距传感器 可燃气体浓度传感器 高精度温度传感器 2. 软件开发情况总体介绍 RTOS 选择: rt-thread 在软件开发上，考虑到此模块外接的设备较多并且需要网络协议栈，裸机开发可能会比较棘手，因此基于 RTOS 完成开发。&#xA;比较常用的 RTOS 是 freeRTOS ，我学习的第一个是 rt-thread，rtt 除了实时内核，对设备驱动也做了抽象，有更易调用的方法和软件包，因此基于 rt-thread 开发该模块的软件。我看过一些 freeRTOS 项目的源码，外设驱动大多是和裸机操作一样基于 HAL 库来完成。rtt 设计一套统一的 api ，和 linux 类似使用 open close read write 来操作设备，此外我更喜欢 rtt 源码风格，其和 linux 风格类似使用全小写+_的方式。</description>
    </item>
  </channel>
</rss>
